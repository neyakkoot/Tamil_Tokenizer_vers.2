{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install Open-Tamil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HML7oci97ic",
        "outputId": "8aac41cd-1465-4384-fdcb-e679ec14f758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Open-Tamil\n",
            "  Downloading Open-Tamil-1.1.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Open-Tamil\n",
            "  Building wheel for Open-Tamil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Open-Tamil: filename=Open_Tamil-1.1-py3-none-any.whl size=2388368 sha256=edbe81781a906e2cd598e8109d0198bfbbf3b715edd645de76f447d2c0dcfedc\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/de/5a/d897a3edbefc5101587607d28b221c86f39482393daed8c18f\n",
            "Successfully built Open-Tamil\n",
            "Installing collected packages: Open-Tamil\n",
            "Successfully installed Open-Tamil-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tamil\n",
        "from tamil.utf8 import get_letters, get_words\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import json\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import re\n",
        "from typing import List, Dict, Tuple, Optional, Union\n",
        "import numpy as np\n",
        "\n",
        "class AdvancedTamilAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"தமிழ் உரை பகுப்பாய்வி துவக்கம்\"\"\"\n",
        "        # அடிப்படை தமிழ் எழுத்துகளை ஏற்றுதல்\n",
        "        self.tamil_letters = tamil.utf8.tamil_letters\n",
        "        self.uyir_letters = tamil.utf8.uyir_letters\n",
        "        self.mei_letters = tamil.utf8.mei_letters\n",
        "        self.uyirmei_letters = tamil.utf8.uyirmei_letters\n",
        "        self.agaram_letters = tamil.utf8.agaram_letters\n",
        "\n",
        "    def load_text(self, source: Union[str, Path], source_type: str = 'file', column_name: str = None) -> str:\n",
        "        \"\"\"\n",
        "        பல்வேறு மூலங்களிலிருந்து உரையை ஏற்றுதல்\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if source_type == 'file':\n",
        "                with open(source, 'r', encoding='utf-8') as f:\n",
        "                    return f.read()\n",
        "            elif source_type == 'csv':\n",
        "                df = pd.read_csv(source, encoding='utf-8')\n",
        "                return '\\n'.join(df[column_name].astype(str).tolist())\n",
        "            else:  # text\n",
        "                return source\n",
        "        except Exception as e:\n",
        "            print(f\"உரை ஏற்றுவதில் பிழை: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def detailed_analysis(self, text: str) -> Dict:\n",
        "        \"\"\"\n",
        "        விரிவான உரை பகுப்பாய்வு\n",
        "        \"\"\"\n",
        "        # அடிப்படை பகுப்பாய்வு\n",
        "        words = get_words(text)\n",
        "        letters = get_letters(text)\n",
        "\n",
        "        # தமிழ் எழுத்துகளை மட்டும் பிரித்தெடுத்தல்\n",
        "        tamil_letters = [letter for letter in letters if tamil.utf8.istamil(letter)]\n",
        "\n",
        "        # எழுத்து வகை பகுப்பாய்வு\n",
        "        letter_types = {\n",
        "            'உயிர்': sum(1 for char in tamil_letters if char in self.uyir_letters),\n",
        "            'மெய்': sum(1 for char in tamil_letters if char in self.mei_letters),\n",
        "            'உயிர்மெய்': sum(1 for char in tamil_letters if char in self.uyirmei_letters),\n",
        "            'அகரம்': sum(1 for char in tamil_letters if char in self.agaram_letters)\n",
        "        }\n",
        "\n",
        "        # சொல் பகுப்பாய்வு\n",
        "        tamil_words = [word for word in words if tamil.utf8.istamil_prefix(word)]\n",
        "        word_lengths = [len(get_letters(word)) for word in tamil_words]\n",
        "\n",
        "        # சொற்களின் அதிர்வெண்\n",
        "        word_freq = Counter(tamil_words)\n",
        "        top_words = dict(word_freq.most_common(10))\n",
        "\n",
        "        # எழுத்துகளின் அதிர்வெண்\n",
        "        char_freq = Counter(tamil_letters)\n",
        "        top_chars = dict(char_freq.most_common(10))\n",
        "\n",
        "        return {\n",
        "            'அடிப்படை_தகவல்': {\n",
        "                'மொத்த_சொற்கள்': len(tamil_words),\n",
        "                'தனித்த_சொற்கள்': len(set(tamil_words)),\n",
        "                'மொத்த_எழுத்துகள்': len(tamil_letters),\n",
        "                'தனித்த_எழுத்துகள்': len(set(tamil_letters)),\n",
        "                'சராசரி_சொல்_நீளம்': np.mean(word_lengths) if word_lengths else 0,\n",
        "                'பெரிய_சொல்': max(tamil_words, key=len) if tamil_words else \"\",\n",
        "                'சிறிய_சொல்': min(tamil_words, key=len) if tamil_words else \"\"\n",
        "            },\n",
        "            'எழுத்து_வகைகள்': letter_types,\n",
        "            'அதிக_பயன்பாட்டு_சொற்கள்': top_words,\n",
        "            'அதிக_பயன்பாட்டு_எழுத்துகள்': top_chars\n",
        "        }\n",
        "\n",
        "    def generate_visualizations(self, analysis_results: Dict, output_dir: str = None):\n",
        "        \"\"\"\n",
        "        பகுப்பாய்வு முடிவுகளுக்கான ஊடாடும் காட்சிப்படுத்தல்கள்\n",
        "        \"\"\"\n",
        "        # உள்ளீடு சரிபார்ப்பு\n",
        "        if not analysis_results:\n",
        "            return None\n",
        "\n",
        "        # 1. சொல் அதிர்வெண் வரைபடம்\n",
        "        word_freq_data = pd.DataFrame({\n",
        "            'சொற்கள்': list(analysis_results['அதிக_பயன்பாட்டு_சொற்கள்'].keys()),\n",
        "            'அதிர்வெண்': list(analysis_results['அதிக_பயன்பாட்டு_சொற்கள்'].values())\n",
        "        })\n",
        "        word_freq_fig = px.bar(\n",
        "            word_freq_data,\n",
        "            x='சொற்கள்',\n",
        "            y='அதிர்வெண்',\n",
        "            title='அதிக பயன்பாட்டிலுள்ள சொற்கள்'\n",
        "        )\n",
        "\n",
        "        # 2. எழுத்து வகை பை வரைபடம்\n",
        "        letter_types_fig = px.pie(\n",
        "            values=list(analysis_results['எழுத்து_வகைகள்'].values()),\n",
        "            names=list(analysis_results['எழுத்து_வகைகள்'].keys()),\n",
        "            title='எழுத்து வகைகள் விநியோகம்'\n",
        "        )\n",
        "\n",
        "        # 3. எழுத்து அதிர்வெண் வரைபடம்\n",
        "        char_freq_data = pd.DataFrame({\n",
        "            'எழுத்துகள்': list(analysis_results['அதிக_பயன்பாட்டு_எழுத்துகள்'].keys()),\n",
        "            'அதிர்வெண்': list(analysis_results['அதிக_பயன்பாட்டு_எழுத்துகள்'].values())\n",
        "        })\n",
        "        char_freq_fig = px.bar(\n",
        "            char_freq_data,\n",
        "            x='எழுத்துகள்',\n",
        "            y='அதிர்வெண்',\n",
        "            title='அதிக பயன்பாட்டிலுள்ள எழுத்துகள்'\n",
        "        )\n",
        "\n",
        "        # தொகுக்கப்பட்ட காட்சி\n",
        "        dashboard = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            specs=[\n",
        "                [{\"type\": \"xy\"}, {\"type\": \"domain\"}],\n",
        "                [{\"type\": \"xy\"}, None]\n",
        "            ],\n",
        "            subplot_titles=(\n",
        "                'அதிக பயன்பாட்டிலுள்ள சொற்கள்',\n",
        "                'எழுத்து வகைகள் விநியோகம்',\n",
        "                'அதிக பயன்பாட்டிலுள்ள எழுத்துகள்'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add traces to dashboard\n",
        "        for trace in word_freq_fig.data:\n",
        "            dashboard.add_trace(trace, row=1, col=1)\n",
        "        for trace in letter_types_fig.data:\n",
        "            dashboard.add_trace(trace, row=1, col=2)\n",
        "        for trace in char_freq_fig.data:\n",
        "            dashboard.add_trace(trace, row=2, col=1)\n",
        "\n",
        "        # Update layout\n",
        "        dashboard.update_layout(\n",
        "            height=800,\n",
        "            width=1200,\n",
        "            showlegend=True,\n",
        "            title_text=\"தமிழ் உரை பகுப்பாய்வு முடிவுகள்\"\n",
        "        )\n",
        "\n",
        "        # Save visualizations if output directory is specified\n",
        "        if output_dir:\n",
        "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "            word_freq_fig.write_html(str(Path(output_dir) / 'word_frequency.html'))\n",
        "            letter_types_fig.write_html(str(Path(output_dir) / 'letter_types.html'))\n",
        "            char_freq_fig.write_html(str(Path(output_dir) / 'char_frequency.html'))\n",
        "            dashboard.write_html(str(Path(output_dir) / 'dashboard.html'))\n",
        "\n",
        "        return {\n",
        "            'word_frequency': word_freq_fig,\n",
        "            'letter_types': letter_types_fig,\n",
        "            'char_frequency': char_freq_fig,\n",
        "            'dashboard': dashboard\n",
        "        }\n",
        "\n",
        "    def save_results(self, results: Dict, output_file: str):\n",
        "        \"\"\"பகுப்பாய்வு முடிவுகளை JSON வடிவில் சேமித்தல்\"\"\"\n",
        "        try:\n",
        "            # Convert results to JSON-serializable format\n",
        "            serializable_results = {\n",
        "                'அடிப்படை_தகவல்': results['அடிப்படை_தகவல்'],\n",
        "                'எழுத்து_வகைகள்': results['எழுத்து_வகைகள்'],\n",
        "                'அதிக_பயன்பாட்டு_சொற்கள்': dict(results['அதிக_பயன்பாட்டு_சொற்கள்']),\n",
        "                'அதிக_பயன்பாட்டு_எழுத்துகள்': dict(results['அதிக_பயன்பாட்டு_எழுத்துகள்'])\n",
        "            }\n",
        "\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(serializable_results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            print(f\"முடிவுகள் {output_file} கோப்பில் சேமிக்கப்பட்டன\")\n",
        "        except Exception as e:\n",
        "            print(f\"முடிவுகளை சேமிக்கும் போது பிழை: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"எடுத்துக்காட்டு பயன்பாடு\"\"\"\n",
        "    # பகுப்பாய்வாளரை உருவாக்குதல்\n",
        "    analyzer = AdvancedTamilAnalyzer()\n",
        "\n",
        "    # சோதனை உரை\n",
        "    test_text = \"\"\"\n",
        "     *வெள்ளமனம் உள்ள நண்பா*\n",
        "\n",
        "புதுவகை உறவொன்றைப்\n",
        "புலனத்தில் பார்த்தேன்\n",
        "அது தருகின்ற உற்சாக\n",
        "மதுவினில் வேர்த்தேன்\n",
        "எதுவரை எங்கள் நட்பு\n",
        "இறைவனைக் கேட்டேன்\n",
        "இது இறக்கும் வரையா\n",
        "நானறிய மாட்டேன்\n",
        "\n",
        "நாலுபேரு பேசுகின்ற\n",
        "நல்லதொரு மனம்\n",
        "வாள்போல வீசுகின்ற\n",
        "சொல்லின் குணம்\n",
        "நூல்போல நூற்றெடுக்கும்\n",
        "நுட்பத்தின் திறம்\n",
        "தோள்மேல ஏற்றெடுக்கும்\n",
        "நட்பிலொரு மரம்\n",
        "\n",
        "கண்ணாலே கண்டதில்ல\n",
        "கரம்பற்றிக் கொண்டதில்ல\n",
        "பின்னாலே என்றாலும்\n",
        "புறம்பேசிச் சென்றதில்ல\n",
        "என்னுடை எழுத்திற்கு\n",
        "பின்னூட்டம் மறந்ததில்ல\n",
        "விண்வரை எழுவென்று\n",
        "புகழாமல் இருந்ததில்ல\n",
        "\n",
        "நெட்டையோ குட்டையோ\n",
        "நான் பார்த்ததில்ல\n",
        "மட்டந்தட்டும் கருத்தும்\n",
        "நான் கேட்டதில்ல\n",
        "சுட்டிக் காட்டிடுவேன்\n",
        "உள்ளமும் வெள்ள\n",
        "கட்டி அணைத்திடணும்\n",
        "அவரை நான் மெல்ல\n",
        "    \"\"\"\n",
        "\n",
        "    # பகுப்பாய்வு செய்தல்\n",
        "    results = analyzer.detailed_analysis(test_text)\n",
        "\n",
        "    # காட்சிப்படுத்தல்களை உருவாக்குதல்\n",
        "    visualizations = analyzer.generate_visualizations(\n",
        "        results,\n",
        "        output_dir='analysis_output'\n",
        "    )\n",
        "\n",
        "    # முடிவுகளை சேமித்தல்\n",
        "    analyzer.save_results(results, 'analysis_results.json')\n",
        "    analyzer.save_results(results, 'analysis_results.txt')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dceQNkskD3T8",
        "outputId": "6f259769-6f6d-4e1f-987e-792f5056e988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "முடிவுகள் analysis_results.json கோப்பில் சேமிக்கப்பட்டன\n",
            "முடிவுகள் analysis_results.txt கோப்பில் சேமிக்கப்பட்டன\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tamil\n",
        "from tamil.utf8 import get_letters, get_words\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import json\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import re\n",
        "from typing import List, Dict, Tuple, Optional, Union\n",
        "import numpy as np\n",
        "\n",
        "class AdvancedTamilAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"தமிழ் உரை பகுப்பாய்வி துவக்கம்\"\"\"\n",
        "        # அடிப்படை தமிழ் எழுத்துகளை ஏற்றுதல்\n",
        "        self.tamil_letters = tamil.utf8.tamil_letters\n",
        "        self.uyir_letters = tamil.utf8.uyir_letters\n",
        "        self.mei_letters = tamil.utf8.mei_letters\n",
        "        self.uyirmei_letters = tamil.utf8.uyirmei_letters\n",
        "        self.agaram_letters = tamil.utf8.agaram_letters\n",
        "\n",
        "    def load_text(self, source: Union[str, Path], source_type: str = 'file', column_name: str = None) -> str:\n",
        "        \"\"\"\n",
        "        பல்வேறு மூலங்களிலிருந்து உரையை ஏற்றுதல்\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if source_type == 'file':\n",
        "                with open(source, 'r', encoding='utf-8') as f:\n",
        "                    return f.read()\n",
        "            elif source_type == 'csv':\n",
        "                df = pd.read_csv(source, encoding='utf-8')\n",
        "                return '\\n'.join(df[column_name].astype(str).tolist())\n",
        "            else:  # text\n",
        "                return source\n",
        "        except Exception as e:\n",
        "            print(f\"உரை ஏற்றுவதில் பிழை: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def detailed_analysis(self, text: str) -> Dict:\n",
        "        \"\"\"\n",
        "        விரிவான உரை பகுப்பாய்வு\n",
        "        \"\"\"\n",
        "        # அடிப்படை பகுப்பாய்வு\n",
        "        words = get_words(text)\n",
        "        letters = get_letters(text)\n",
        "\n",
        "        # தமிழ் எழுத்துகளை மட்டும் பிரித்தெடுத்தல்\n",
        "        tamil_letters = [letter for letter in letters if tamil.utf8.istamil(letter)]\n",
        "\n",
        "        # எழுத்து வகை பகுப்பாய்வு\n",
        "        letter_types = {\n",
        "            'உயிர்': sum(1 for char in tamil_letters if char in self.uyir_letters),\n",
        "            'மெய்': sum(1 for char in tamil_letters if char in self.mei_letters),\n",
        "            'உயிர்மெய்': sum(1 for char in tamil_letters if char in self.uyirmei_letters),\n",
        "            'அகரம்': sum(1 for char in tamil_letters if char in self.agaram_letters)\n",
        "        }\n",
        "\n",
        "        # சொல் பகுப்பாய்வு\n",
        "        tamil_words = [word for word in words if tamil.utf8.istamil_prefix(word)]\n",
        "        word_lengths = [len(get_letters(word)) for word in tamil_words]\n",
        "\n",
        "        # சொற்களின் அதிர்வெண்\n",
        "        word_freq = Counter(tamil_words)\n",
        "        top_words = dict(word_freq.most_common(10))\n",
        "\n",
        "        # எழுத்துகளின் அதிர்வெண்\n",
        "        char_freq = Counter(tamil_letters)\n",
        "        top_chars = dict(char_freq.most_common(10))\n",
        "\n",
        "        return {\n",
        "            'அடிப்படை_தகவல்': {\n",
        "                'மொத்த_சொற்கள்': len(tamil_words),\n",
        "                'தனித்த_சொற்கள்': len(set(tamil_words)),\n",
        "                'மொத்த_எழுத்துகள்': len(tamil_letters),\n",
        "                'தனித்த_எழுத்துகள்': len(set(tamil_letters)),\n",
        "                'சராசரி_சொல்_நீளம்': np.mean(word_lengths) if word_lengths else 0,\n",
        "                'பெரிய_சொல்': max(tamil_words, key=len) if tamil_words else \"\",\n",
        "                'சிறிய_சொல்': min(tamil_words, key=len) if tamil_words else \"\"\n",
        "            },\n",
        "            'எழுத்து_வகைகள்': letter_types,\n",
        "            'அதிக_பயன்பாட்டு_சொற்கள்': top_words,\n",
        "            'அதிக_பயன்பாட்டு_எழுத்துகள்': top_chars\n",
        "        }\n",
        "\n",
        "    def generate_visualizations(self, analysis_results: Dict, output_dir: str = None):\n",
        "        \"\"\"\n",
        "        பகுப்பாய்வு முடிவுகளுக்கான ஊடாடும் காட்சிப்படுத்தல்கள்\n",
        "        \"\"\"\n",
        "        # உள்ளீடு சரிபார்ப்பு\n",
        "        if not analysis_results:\n",
        "            return None\n",
        "\n",
        "        # 1. சொல் அதிர்வெண் வரைபடம்\n",
        "        word_freq_data = pd.DataFrame({\n",
        "            'சொற்கள்': list(analysis_results['அதிக_பயன்பாட்டு_சொற்கள்'].keys()),\n",
        "            'அதிர்வெண்': list(analysis_results['அதிக_பயன்பாட்டு_சொற்கள்'].values())\n",
        "        })\n",
        "        word_freq_fig = px.bar(\n",
        "            word_freq_data,\n",
        "            x='சொற்கள்',\n",
        "            y='அதிர்வெண்',\n",
        "            title='அதிக பயன்பாட்டிலுள்ள சொற்கள்'\n",
        "        )\n",
        "\n",
        "        # 2. எழுத்து வகை பை வரைபடம்\n",
        "        letter_types_fig = px.pie(\n",
        "            values=list(analysis_results['எழுத்து_வகைகள்'].values()),\n",
        "            names=list(analysis_results['எழுத்து_வகைகள்'].keys()),\n",
        "            title='எழுத்து வகைகள் விநியோகம்'\n",
        "        )\n",
        "\n",
        "        # 3. எழுத்து அதிர்வெண் வரைபடம்\n",
        "        char_freq_data = pd.DataFrame({\n",
        "            'எழுத்துகள்': list(analysis_results['அதிக_பயன்பாட்டு_எழுத்துகள்'].keys()),\n",
        "            'அதிர்வெண்': list(analysis_results['அதிக_பயன்பாட்டு_எழுத்துகள்'].values())\n",
        "        })\n",
        "        char_freq_fig = px.bar(\n",
        "            char_freq_data,\n",
        "            x='எழுத்துகள்',\n",
        "            y='அதிர்வெண்',\n",
        "            title='அதிக பயன்பாட்டிலுள்ள எழுத்துகள்'\n",
        "        )\n",
        "\n",
        "        # தொகுக்கப்பட்ட காட்சி\n",
        "        dashboard = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            specs=[\n",
        "                [{\"type\": \"xy\"}, {\"type\": \"domain\"}],\n",
        "                [{\"type\": \"xy\"}, None]\n",
        "            ],\n",
        "            subplot_titles=(\n",
        "                'அதிக பயன்பாட்டிலுள்ள சொற்கள்',\n",
        "                'எழுத்து வகைகள் விநியோகம்',\n",
        "                'அதிக பயன்பாட்டிலுள்ள எழுத்துகள்'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add traces to dashboard\n",
        "        for trace in word_freq_fig.data:\n",
        "            dashboard.add_trace(trace, row=1, col=1)\n",
        "        for trace in letter_types_fig.data:\n",
        "            dashboard.add_trace(trace, row=1, col=2)\n",
        "        for trace in char_freq_fig.data:\n",
        "            dashboard.add_trace(trace, row=2, col=1)\n",
        "\n",
        "        # Update layout\n",
        "        dashboard.update_layout(\n",
        "            height=800,\n",
        "            width=1200,\n",
        "            showlegend=True,\n",
        "            title_text=\"தமிழ் உரை பகுப்பாய்வு முடிவுகள்\"\n",
        "        )\n",
        "\n",
        "        # Save visualizations if output directory is specified\n",
        "        if output_dir:\n",
        "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "            word_freq_fig.write_html(str(Path(output_dir) / 'word_frequency.html'))\n",
        "            letter_types_fig.write_html(str(Path(output_dir) / 'letter_types.html'))\n",
        "            char_freq_fig.write_html(str(Path(output_dir) / 'char_frequency.html'))\n",
        "            dashboard.write_html(str(Path(output_dir) / 'dashboard.html'))\n",
        "\n",
        "        return {\n",
        "            'word_frequency': word_freq_fig,\n",
        "            'letter_types': letter_types_fig,\n",
        "            'char_frequency': char_freq_fig,\n",
        "            'dashboard': dashboard\n",
        "        }\n",
        "\n",
        "    def save_results(self, results: Dict, output_file: str):\n",
        "        \"\"\"பகுப்பாய்வு முடிவுகளை JSON வடிவில் சேமித்தல்\"\"\"\n",
        "        try:\n",
        "            # Convert results to JSON-serializable format\n",
        "            serializable_results = {\n",
        "                'அடிப்படை_தகவல்': results['அடிப்படை_தகவல்'],\n",
        "                'எழுத்து_வகைகள்': results['எழுத்து_வகைகள்'],\n",
        "                'அதிக_பயன்பாட்டு_சொற்கள்': dict(results['அதிக_பயன்பாட்டு_சொற்கள்']),\n",
        "                'அதிக_பயன்பாட்டு_எழுத்துகள்': dict(results['அதிக_பயன்பாட்டு_எழுத்துகள்'])\n",
        "            }\n",
        "\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(serializable_results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            print(f\"முடிவுகள் {output_file} கோப்பில் சேமிக்கப்பட்டன\")\n",
        "        except Exception as e:\n",
        "            print(f\"முடிவுகளை சேமிக்கும் போது பிழை: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"எடுத்துக்காட்டு பயன்பாடு\"\"\"\n",
        "    # பகுப்பாய்வாளரை உருவாக்குதல்\n",
        "    analyzer = AdvancedTamilAnalyzer()\n",
        "\n",
        "    # சோதனை உரை\n",
        "    test_text = \"testfile.csv\"\n",
        "\n",
        "    # பகுப்பாய்வு செய்தல்\n",
        "    results = analyzer.detailed_analysis(test_text)\n",
        "\n",
        "    # காட்சிப்படுத்தல்களை உருவாக்குதல்\n",
        "    visualizations = analyzer.generate_visualizations(\n",
        "        results,\n",
        "        output_dir='analysis_output'\n",
        "    )\n",
        "\n",
        "    # முடிவுகளை சேமித்தல்\n",
        "    analyzer.save_results(results, 'analysis_results1.json')\n",
        "    analyzer.save_results(results, 'analysis_results1.txt')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "M3c7RCg7-_rj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d4812f2e-805d-4323-94a2-2389075ca4c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "முடிவுகள் analysis_results1.json கோப்பில் சேமிக்கப்பட்டன\n",
            "முடிவுகள் analysis_results1.txt கோப்பில் சேமிக்கப்பட்டன\n"
          ]
        }
      ]
    }
  ]
}