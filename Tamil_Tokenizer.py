# -*- coding: utf-8 -*-
"""Tamil_Tokenizer_ver.1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cw4AQ6YMzQXON7hCPxNDCw4mOf90O2RY
"""



import tamil
import re
from collections import Counter
import csv
import json
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt

class TamilTextAnalyzer:
    def __init__(self):
        self.tamil_letters = 'அ-ஔக-னா-ூெ-ௌ'
        self.numbers = '0-9'
        self.special_chars = r'[\s,.!?;:\"\'(){}\[\]_+=<>/\\|~`@#$%^&*]'

        # உயிர் எழுத்துகள்
        self.uyir = ['அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ']

        # மெய் எழுத்துகள்
        self.mei = ['க்', 'ங்', 'ச்', 'ஞ்', 'ட்', 'ண்', 'த்', 'ந்', 'ப்', 'ம்',
                   'ய்', 'ர்', 'ல்', 'வ்', 'ழ்', 'ள்', 'ற்', 'ன்']

    def load_text_file(self, file_path):
        """உரைக் கோப்பை படித்தல்"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        except Exception as e:
            print(f"கோப்பு படிக்கும் பிழை: {str(e)}")
            return ""

    def load_csv_data(self, file_path, column_name):
        """CSV கோப்பிலிருந்து குறிப்பிட்ட நெடுவரிசையின் தரவைப் படித்தல்"""
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            if column_name in df.columns:
                return '\n'.join(df[column_name].astype(str).tolist())
            else:
                print(f"நெடுவரிசை '{column_name}' கிடைக்கவில்லை")
                return ""
        except Exception as e:
            print(f"CSV கோப்பு படிக்கும் பிழை: {str(e)}")
            return ""

    def tokenize(self, text):
        """சொற்களாகப் பிரித்தல்"""
        if not text:
            return []
        text = re.sub(self.special_chars, ' ', text)
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return [token for token in text.split(' ') if token]

    def get_character_tokens(self, text):
        """எழுத்துக்களாகப் பிரித்தல்"""
        if not text:
            return []
        chars = []
        i = 0
        while i < len(text):
            if i + 1 < len(text) and text[i+1] in 'ா-ூெ-ௌ':
                chars.append(text[i:i+2])
                i += 2
            else:
                chars.append(text[i])
                i += 1
        return [char for char in chars if not re.match(r'\s', char)]

    def analyze_text(self, text):
        """விரிவான உரை பகுப்பாய்வு"""
        words = self.tokenize(text)
        chars = self.get_character_tokens(text)

        # சொற்களின் அதிர்வெண்
        word_freq = Counter(words)
        top_words = dict(word_freq.most_common(10))

        # எழுத்துகளின் அதிர்வெண்
        char_freq = Counter(chars)
        top_chars = dict(char_freq.most_common(10))

        # சொற்களின் நீளம் பகுப்பாய்வு
        word_lengths = [len(self.get_character_tokens(word)) for word in words]
        avg_word_length = sum(word_lengths) / len(word_lengths) if word_lengths else 0

        # உயிர் எழுத்துகள் மற்றும் மெய் எழுத்துகள் எண்ணிக்கை
        uyir_count = sum(1 for char in chars if char in self.uyir)
        mei_count = sum(1 for char in chars if char in self.mei)

        return {
            'மொத்த_சொற்கள்': len(words),
            'தனித்த_சொற்கள்': len(set(words)),
            'மொத்த_எழுத்துகள்': len(chars),
            'தனித்த_எழுத்துகள்': len(set(chars)),
            'சராசரி_சொல்_நீளம்': round(avg_word_length, 2),
            'அதிக_பயன்பாட்டு_சொற்கள்': top_words,
            'அதிக_பயன்பாட்டு_எழுத்துகள்': top_chars,
            'உயிர்_எழுத்துகள்_எண்ணிக்கை': uyir_count,
            'மெய்_எழுத்துகள்_எண்ணிக்கை': mei_count
        }

    def save_analysis_results(self, results, output_file):
        """பகுப்பாய்வு முடிவுகளை சேமித்தல்"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"முடிவுகள் {output_file} கோப்பில் சேமிக்கப்பட்டன")
        except Exception as e:
            print(f"முடிவுகளை சேமிக்கும் போது பிழை: {str(e)}")

    def plot_word_frequency(self, text, output_file=None):
        """சொற்களின் அதிர்வெண் வரைபடம்"""
        words = self.tokenize(text)
        word_freq = Counter(words).most_common(10)

        words, frequencies = zip(*word_freq)
        plt.figure(figsize=(12, 6))
        plt.bar(words, frequencies)
        plt.xticks(rotation=45, ha='right')
        plt.title('அதிக பயன்பாட்டிலுள்ள சொற்கள்')
        plt.xlabel('சொற்கள்')
        plt.ylabel('அதிர்வெண்')

        if output_file:
            plt.savefig(output_file, bbox_inches='tight')
            plt.close()
        else:
            plt.show()

def main():
    analyzer = TamilTextAnalyzer()

    # உதாரணத்திற்கான பயன்பாடு
    sample_text = """
    தமிழ் இலக்கியம் தொன்மையானது. சங்கவிலக்கியம், பக்தியிலக்கியம், காப்பியவிலக்கியம் எனப்
    பல்வேறு வகைகள் உண்டு. தமிழ்மொழி திராவிட மொழிக் குடும்பத்தைச் சேர்ந்தது.
    தமிழ் மொழியில் ஏராளமான இலக்கிய வளம் உள்ளது.
    """

    # CSV கோப்பிலிருந்து படித்தல்
    # text = analyzer.load_csv_data('tamil_data.csv', 'content')

    # உரைக் கோப்பிலிருந்து படித்தல்
    # text = analyzer.load_text_file('tamil_text.txt')

    # பகுப்பாய்வு செய்தல்
    results = analyzer.analyze_text(sample_text)

    # முடிவுகளைக் காட்டுதல்
    print("\nபகுப்பாய்வு முடிவுகள்:")
    for key, value in results.items():
        print(f"{key}: {value}")

    # முடிவுகளை JSON கோப்பில் சேமித்தல்
    analyzer.save_analysis_results(results, 'analysis_results.json')

    # சொல் அதிர்வெண் வரைபடம்
    #analyzer.plot_word_frequency(sample_text, 'word_frequency.png')

if __name__ == "__main__":
    main()