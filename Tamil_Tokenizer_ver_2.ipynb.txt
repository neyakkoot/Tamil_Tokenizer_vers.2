{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install Open-Tamil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HML7oci97ic",
        "outputId": "a023e2fc-de3d-497d-a9bb-da61ea07d6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Open-Tamil\n",
            "  Downloading Open-Tamil-1.1.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Open-Tamil\n",
            "  Building wheel for Open-Tamil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Open-Tamil: filename=Open_Tamil-1.1-py3-none-any.whl size=2388368 sha256=b7b3a1e2f0877ac2fd7e265dd1ec71fc2b0f9ee8738b6a058ff30172de6c80e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/de/5a/d897a3edbefc5101587607d28b221c86f39482393daed8c18f\n",
            "Successfully built Open-Tamil\n",
            "Installing collected packages: Open-Tamil\n",
            "Successfully installed Open-Tamil-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tamil\n",
        "from tamil.utf8 import get_letters, get_words\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import json\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import re\n",
        "from typing import List, Dict, Tuple, Optional, Union\n",
        "import numpy as np\n",
        "\n",
        "class AdvancedTamilAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"தமிழ் உரை பகுப்பாய்வி துவக்கம்\"\"\"\n",
        "        # அடிப்படை தமிழ் எழுத்துகளை ஏற்றுதல்\n",
        "        self.tamil_letters = tamil.utf8.tamil_letters\n",
        "        self.uyir_letters = tamil.utf8.uyir_letters\n",
        "        self.mei_letters = tamil.utf8.mei_letters\n",
        "        self.uyirmei_letters = tamil.utf8.uyirmei_letters\n",
        "        self.agaram_letters = tamil.utf8.agaram_letters\n",
        "\n",
        "    def load_text(self, source: Union[str, Path], source_type: str = 'file', column_name: str = None) -> str:\n",
        "        \"\"\"\n",
        "        பல்வேறு மூலங்களிலிருந்து உரையை ஏற்றுதல்\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if source_type == 'file':\n",
        "                with open(source, 'r', encoding='utf-8') as f:\n",
        "                    return f.read()\n",
        "            elif source_type == 'csv':\n",
        "                df = pd.read_csv(source, encoding='utf-8')\n",
        "                return '\\n'.join(df[column_name].astype(str).tolist())\n",
        "            else:  # text\n",
        "                return source\n",
        "        except Exception as e:\n",
        "            print(f\"உரை ஏற்றுவதில் பிழை: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def detailed_analysis(self, text: str) -> Dict:\n",
        "        \"\"\"\n",
        "        விரிவான உரை பகுப்பாய்வு\n",
        "        \"\"\"\n",
        "        # அடிப்படை பகுப்பாய்வு\n",
        "        words = get_words(text)\n",
        "        letters = get_letters(text)\n",
        "\n",
        "        # தமிழ் எழுத்துகளை மட்டும் பிரித்தெடுத்தல்\n",
        "        tamil_letters = [letter for letter in letters if tamil.utf8.istamil(letter)]\n",
        "\n",
        "        # எழுத்து வகை பகுப்பாய்வு\n",
        "        letter_types = {\n",
        "            'உயிர்': sum(1 for char in tamil_letters if char in self.uyir_letters),\n",
        "            'மெய்': sum(1 for char in tamil_letters if char in self.mei_letters),\n",
        "            'உயிர்மெய்': sum(1 for char in tamil_letters if char in self.uyirmei_letters),\n",
        "            'அகரம்': sum(1 for char in tamil_letters if char in self.agaram_letters)\n",
        "        }\n",
        "\n",
        "        # சொல் பகுப்பாய்வு\n",
        "        tamil_words = [word for word in words if tamil.utf8.istamil_prefix(word)]\n",
        "        word_lengths = [len(get_letters(word)) for word in tamil_words]\n",
        "\n",
        "        # சொற்களின் அதிர்வெண்\n",
        "        word_freq = Counter(tamil_words)\n",
        "        top_words = dict(word_freq.most_common(10))\n",
        "\n",
        "        # எழுத்துகளின் அதிர்வெண்\n",
        "        char_freq = Counter(tamil_letters)\n",
        "        top_chars = dict(char_freq.most_common(10))\n",
        "\n",
        "        return {\n",
        "            'அடிப்படை_தகவல்': {\n",
        "                'மொத்த_சொற்கள்': len(tamil_words),\n",
        "                'தனித்த_சொற்கள்': len(set(tamil_words)),\n",
        "                'மொத்த_எழுத்துகள்': len(tamil_letters),\n",
        "                'தனித்த_எழுத்துகள்': len(set(tamil_letters)),\n",
        "                'சராசரி_சொல்_நீளம்': np.mean(word_lengths) if word_lengths else 0,\n",
        "                'பெரிய_சொல்': max(tamil_words, key=len) if tamil_words else \"\",\n",
        "                'சிறிய_சொல்': min(tamil_words, key=len) if tamil_words else \"\"\n",
        "            },\n",
        "            'எழுத்து_வகைகள்': letter_types,\n",
        "            'அதிக_பயன்பாட்டு_சொற்கள்': top_words,\n",
        "            'அதிக_பயன்பாட்டு_எழுத்துகள்': top_chars\n",
        "        }\n",
        "\n",
        "    def generate_visualizations(self, analysis_results: Dict, output_dir: str = None):\n",
        "        \"\"\"\n",
        "        பகுப்பாய்வு முடிவுகளுக்கான ஊடாடும் காட்சிப்படுத்தல்கள்\n",
        "        \"\"\"\n",
        "        # உள்ளீடு சரிபார்ப்பு\n",
        "        if not analysis_results:\n",
        "            return None\n",
        "\n",
        "        # 1. சொல் அதிர்வெண் வரைபடம்\n",
        "        word_freq_data = pd.DataFrame({\n",
        "            'சொற்கள்': list(analysis_results['அதிக_பயன்பாட்டு_சொற்கள்'].keys()),\n",
        "            'அதிர்வெண்': list(analysis_results['அதிக_பயன்பாட்டு_சொற்கள்'].values())\n",
        "        })\n",
        "        word_freq_fig = px.bar(\n",
        "            word_freq_data,\n",
        "            x='சொற்கள்',\n",
        "            y='அதிர்வெண்',\n",
        "            title='அதிக பயன்பாட்டிலுள்ள சொற்கள்'\n",
        "        )\n",
        "\n",
        "        # 2. எழுத்து வகை பை வரைபடம்\n",
        "        letter_types_fig = px.pie(\n",
        "            values=list(analysis_results['எழுத்து_வகைகள்'].values()),\n",
        "            names=list(analysis_results['எழுத்து_வகைகள்'].keys()),\n",
        "            title='எழுத்து வகைகள் விநியோகம்'\n",
        "        )\n",
        "\n",
        "        # 3. எழுத்து அதிர்வெண் வரைபடம்\n",
        "        char_freq_data = pd.DataFrame({\n",
        "            'எழுத்துகள்': list(analysis_results['அதிக_பயன்பாட்டு_எழுத்துகள்'].keys()),\n",
        "            'அதிர்வெண்': list(analysis_results['அதிக_பயன்பாட்டு_எழுத்துகள்'].values())\n",
        "        })\n",
        "        char_freq_fig = px.bar(\n",
        "            char_freq_data,\n",
        "            x='எழுத்துகள்',\n",
        "            y='அதிர்வெண்',\n",
        "            title='அதிக பயன்பாட்டிலுள்ள எழுத்துகள்'\n",
        "        )\n",
        "\n",
        "        # தொகுக்கப்பட்ட காட்சி\n",
        "        dashboard = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            specs=[\n",
        "                [{\"type\": \"xy\"}, {\"type\": \"domain\"}],\n",
        "                [{\"type\": \"xy\"}, None]\n",
        "            ],\n",
        "            subplot_titles=(\n",
        "                'அதிக பயன்பாட்டிலுள்ள சொற்கள்',\n",
        "                'எழுத்து வகைகள் விநியோகம்',\n",
        "                'அதிக பயன்பாட்டிலுள்ள எழுத்துகள்'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add traces to dashboard\n",
        "        for trace in word_freq_fig.data:\n",
        "            dashboard.add_trace(trace, row=1, col=1)\n",
        "        for trace in letter_types_fig.data:\n",
        "            dashboard.add_trace(trace, row=1, col=2)\n",
        "        for trace in char_freq_fig.data:\n",
        "            dashboard.add_trace(trace, row=2, col=1)\n",
        "\n",
        "        # Update layout\n",
        "        dashboard.update_layout(\n",
        "            height=800,\n",
        "            width=1200,\n",
        "            showlegend=True,\n",
        "            title_text=\"தமிழ் உரை பகுப்பாய்வு முடிவுகள்\"\n",
        "        )\n",
        "\n",
        "        # Save visualizations if output directory is specified\n",
        "        if output_dir:\n",
        "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "            word_freq_fig.write_html(str(Path(output_dir) / 'word_frequency.html'))\n",
        "            letter_types_fig.write_html(str(Path(output_dir) / 'letter_types.html'))\n",
        "            char_freq_fig.write_html(str(Path(output_dir) / 'char_frequency.html'))\n",
        "            dashboard.write_html(str(Path(output_dir) / 'dashboard.html'))\n",
        "\n",
        "        return {\n",
        "            'word_frequency': word_freq_fig,\n",
        "            'letter_types': letter_types_fig,\n",
        "            'char_frequency': char_freq_fig,\n",
        "            'dashboard': dashboard\n",
        "        }\n",
        "\n",
        "    def save_results(self, results: Dict, output_file: str):\n",
        "        \"\"\"பகுப்பாய்வு முடிவுகளை JSON வடிவில் சேமித்தல்\"\"\"\n",
        "        try:\n",
        "            # Convert results to JSON-serializable format\n",
        "            serializable_results = {\n",
        "                'அடிப்படை_தகவல்': results['அடிப்படை_தகவல்'],\n",
        "                'எழுத்து_வகைகள்': results['எழுத்து_வகைகள்'],\n",
        "                'அதிக_பயன்பாட்டு_சொற்கள்': dict(results['அதிக_பயன்பாட்டு_சொற்கள்']),\n",
        "                'அதிக_பயன்பாட்டு_எழுத்துகள்': dict(results['அதிக_பயன்பாட்டு_எழுத்துகள்'])\n",
        "            }\n",
        "\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(serializable_results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            print(f\"முடிவுகள் {output_file} கோப்பில் சேமிக்கப்பட்டன\")\n",
        "        except Exception as e:\n",
        "            print(f\"முடிவுகளை சேமிக்கும் போது பிழை: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"எடுத்துக்காட்டு பயன்பாடு\"\"\"\n",
        "    # பகுப்பாய்வாளரை உருவாக்குதல்\n",
        "    analyzer = AdvancedTamilAnalyzer()\n",
        "\n",
        "    # சோதனை உரை\n",
        "    test_text = \"\"\"\n",
        "    தமிழ் இலக்கியம் தொன்மையானது. சங்க இலக்கியம், பக்தி இலக்கியம், காப்பிய இலக்கியம் என\n",
        "    பல்வேறு வகைகள் உண்டு. தமிழ் மொழி திராவிட மொழிக் குடும்பத்தைச் சேர்ந்தது.\n",
        "    தமிழ் மொழியில் ஏராளமான இலக்கிய வளம் உள்ளது.\n",
        "    \"\"\"\n",
        "\n",
        "    # பகுப்பாய்வு செய்தல்\n",
        "    results = analyzer.detailed_analysis(test_text)\n",
        "\n",
        "    # காட்சிப்படுத்தல்களை உருவாக்குதல்\n",
        "    visualizations = analyzer.generate_visualizations(\n",
        "        results,\n",
        "        output_dir='analysis_output'\n",
        "    )\n",
        "\n",
        "    # முடிவுகளை சேமித்தல்\n",
        "    analyzer.save_results(results, 'analysis_results.json')\n",
        "    analyzer.save_results(results, 'analysis_results.')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dceQNkskD3T8",
        "outputId": "1c012bd9-18eb-4205-97ff-e0252bbe5f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "முடிவுகள் analysis_results.json கோப்பில் சேமிக்கப்பட்டன\n"
          ]
        }
      ]
    }
  ]
}